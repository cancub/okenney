{% extends "layout.html" %}

{% block title %}
<title>The 2020s: A Prediction</title>
{% endblock %}

{% block description %}
<meta name="description" content="Regardless of who you are or what life you lead in the 20s, you will experience a seismic shift in how the world functions. How it affects you depends on your lucidity, location and luck.">
{% endblock %}

{% block head %}
<link rel="stylesheet" href="/styles/article.css">
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
{% endblock %}

{% block content_column %}
<p>
    This is the decade where the blind pursuit of growth-at-all-costs leads to a reality that was once the stuff of science fiction and fever dreams. The familiar, incremental improvements made possible through the brute force of human ingenuity will appear quaint in retrospect when compared to the monumental advances we are about to experience.
</p>
<p>
    These advances will no longer be produced by the tools of old: the physical, the mathematical, the logical. No, these advances will be produced by a new set of tools: cold, inorganic minds. Minds that we do not fully understand. Minds whose complexity more and more rivals our own. Minds which have already shown a prediliction for highlighting, if not enhancing, our prejudices and blind spots. Undoubtedly these minds will facilitate the ever-increasing levels of convenience that we have come to expect, but if history has shown us anything about humanity's relationship with new tools, it is this: we are adept at imaginging them in our utopia and inadequate at envisioning its potential for suffering.
</p>
<p>
    Part Prometheus's fire, part Pandora's box. Welcome to the 2020s: The Age of AI.
</p>

<p>
    We humans make and use tools. It's kind of our thing. There are many reasons why we're capable of such higher thought as "where do I go after I die?" or "can morality truly be objective?" or
</p>
<blockquote class="twitter-tweet" data-lang="en">
    <p lang="en" dir="ltr">I have never seen a thin person drinking Diet Coke.</p>&mdash; Donald J. Trump
    (@realDonaldTrump) <a
        href="https://twitter.com/realDonaldTrump/status/257552283850653696?ref_src=twsrc%5Etfw">October 14, 2012</a>
</blockquote>
<p>
    ...but we never would have made it to this point if one of our ancestors didn't happen upon a smashed rock and think ".....shit, I should use this for something. Killing stuff, maybe." From that moment to the one we are currently living, it's impossible to tell the story of our species without describing our relationship with tools, how each addition shapes the next stage of our evolution of our bodies and minds.
</p>
<p class="quote">
    <span>AI is a tsunami: born from a seismic event in relative obscurity, it appears on the horrizon to awe and wonder before escaping its world and swallowing up anything not nailed down in the ours</span>
</p>
<p>
    Until now, our co-evolution with tools has typically followed a boilerplate narrative. Choppy tool arrives. Apes chop stuff. Apes get more resources than before. Apes have more time than before. Apes spend newfound time doing ape things like sleeping, exploring, sexing and even thinking. Some of the time, apes think about the tool: what it is, what it does, what could be changed. Apes try several modifications to the tool. Through trial and error, apes eventually improve chop-to-energy ratio or make a new choppy tool altogether. Apes chop even more stuff, rinse, repeat. We can apply this same logic to every new tool that comes our way, from fire to hammers to microwaves to the shake weight. It is, in a word, predictable.
</p>
<figure>
    <img src="/images/shake-weight.gif"/>
    <figcaption>Pictured: the pinnacle of human enginuity</figcaption>
</figure>
<p>
    The predictability of this human-tool co-evolution goes out the window when the tools themselves become a variable, rapidly morphing in unimaginebable ways in response to the users' desires and even their very nature. If stones were the tide, with its reliable ebbs and flows, and machines were the waves, periodically cresting and crashing, chipping away at the edges of our world, then AI amounts to a tsunami: born in obscurity from a seismic event, appearing on the horrizon to awe and wonder before breaching the boundary of its world and swallowing up all that which is not nailed down in ours.
</p>
<p>
    This is -- to be sure -- an extraordinary claim. And, as many a great student of the universe has said, <a href="https://rationalwiki.org/wiki/Extraordinary_claims_require_extraordinary_evidence" target="_blank">extraordinary claims require extraordinary evidence</a>. So let's set aside the hyperbole and the "holy shit the baby has a gun" alarmism for a moment to study two recent tools that caused monumental shifts in the trajectory of our species: the internal combustion engine and the internet. By comparing these tools with the one that is now on our shores, we can illustrate what makes this new tool so different, how it will affect our lives over the next 10 years and why its important -- if not necessary -- to sound the alarm and plan some routes to higher ground.
</p>
<figure>
    <img src="/images/baby-gun.jpg" />
    <figcaption>Jesus! What the -- how the fuck did she get a gun?! We don't even own a gun!</figcaption>
</figure>
<p>
    To start with, the internal combustion engine and the internet were both designed to acheive very specific goals. The impacts of each are indeed very broad, to the degree that they occasionally overlap (who among us still pays to load their messages and photos into a truck to be and shipped cross-country?), but while both tools have a complexity of moving parts that can at times require advanced degrees to truly understand, their success can always be measured by a finite number of metrics.
</p>
<p>
    Engines are judged by the quantity fo rotational energy produced for each unit of chemical/electrical energy consumed. The internet: the rate and coherence of information being received between distant network interfaces. This is why Toyota and AT&T use such practical values as "miles per gallon" and "bits per second" rather than "¯\_(ツ)_/¯ better than before?"
</p>
<p>
    As you've likely experienced yourself, however, the actual performance of any tool can vary from one day to the next. But this fluctuation isn't caused by the alignment of the stars or how the tool is feeling that particular day. Indeed, Further, the engineering teams who design these tools have such an acute understanding of the product that they suggest , with many professions existing solely to diagnose issues and . we can once again observe the nature of the system -- the components, their connections, their inputs -- to poke, prod, troubleshoot and voila, there's yer problem.
</p>
<figure>
    <img src="/images/opossum-car.jpg" />
    <figcaption>Just give him the keys; it's his car now</figcaption>
</figure>
<p>
    Maybe there's a blown fuse or an maybe someone set some strange routes or maybe <a href="https://www.nationalgeographic.org/thisday/sep9/worlds-first-computer-bug/" target="_blank">there's a litteral bug</a> that wanted to go down in the most monumental blaze of glory in the history of bugs. In any case, the problem isn't ephemeral, it is tangible, discrete and waiting to be found.
</p>
<p>
    You don't stop improving though, and the engineering teams who design these tools have such an acute understanding of the parts that make the whole that they can hone in on specific areas to improve , thus continuing the continual improvement cycle. These concepts of repair and improvement can both be described with this flow chart:
</p>
Select a component or subsystem
Can it be tuned?
tune it
did that improve the output
keep it

<p>
    Now consider AI (note: deep learning, but there's not a lot of AI that's *not* deep learning these days). You've surely heard a lot of talk around AI (it can drive your car! identify your face! make you vote for a despot!), but how does it do what it does? GPUs, right? GPUS, data and... code? I mean, yeah, that's technically correct, but we also just described a video game. If that's all you know, you're not alone.
</p>
<p>
    Even in a world where a story can break and spread across the planet overnight, and even as AI has rapidly filtered into most aspects of your life, you don't see too many stories about what makes it tick and why that might be a problem. Sure, there are <a href="https://www.cnn.com/search?size=10&q=%22deep%20learning%22" target="_blank">boatloads of stories about the final products</a>, but you'll be hard-pressed to find a profile on what gives them life.
</p>
<p>
    Science is not click-baitable. It's even a stretch to call it entertaining, especialy when there's a lack of easily-digestable images that relate to the topic. Click on that last link. I don't know when you're reading this article -- I may have written it years ago -- but one thing I know for sure is that most of the thumbnails in those results fall into one of two categories:
    a) A person mentioned in the story
    b) robot hands
    Compare that to <a href="https://www.cnn.com/search?size=10&q=%22black%20hole%22" target="_blank">this sexy set of links<a> about another hyper-technical topic: black holes. I can't pretend that I spend much time thinking about black holes, but I'll click any link with the title X and the image Y. Thus, to get those valuabel clicks, discussions of AI in the media are almost always presented at a superficial, tourists-gawking-at-the-ocean-receding level.
</p>
<figure>
    <img src="/images/tsunami.jpg" />
    <figcaption>Honey! Come check it out! There's sand dollars!</figcaption>
</figure>
<p>
    It's because of this ineffective and dull science communication that AI is often mistaken for just another fancy tool that software developers have cooked up. We accept <a href="https://www.engadget.com/2017/03/08/burger-flipping-robot-flippy/" target="_blank">a burger-flipping robot</a>, because it's a simple, 1-2-3 process. _Of course_ some nerds in MIT could replace a teenager's job as their summer project. But when it comes to, say, making an emergency landing of an Airbus on the Hudson River, that's when the skepticism starts to seep in. How could we ever create an AI capable of replacing the Sully?
</p>
<p>
    This underestimation of the potential of AI stems from a lack of understanding of the roles of researchers. What you need to realize is that these people are not software developers. In fact, a successful AI researcher will have more in common with your favourite grade school teacher than they will with Bill Gates.
</p>
<p>
    That English teacher who inspired you to be a screenwriter or that math teacher who set your down the path of engineering, they weren't born with the innate ability to upgrade your brain's software, and their talent for transfering knowledge doesn't come from enthusiasm alone. They spent years of their life studying how little minds like yours work and are continually looking for the ways to improve their techniques.
</p>
<p>
    This is what we call pedagogy and it's what separates the good teachers from the bad. Poor pedagogy can lead you to feel like a moron because you just can't "get" a concept, while excellent pedagogy can lead you to feel like you're a "natural."
</p>
<p>
    A more formal description of pedagogy would be "the theory of teaching and learning." It concerns itself with the environmental and societal factors which influence students' learning capacity and styles as well as the various teaching techniques which can be employed to optimize this learning.
</p>
<p>
    Why do we spend decades moulding these minds to perform a specific role in our society? Why don't we just fast track the process by cracking open some little skulls and rewiring things until we get the result we want? 
</p>
<figure>
    <img src="/images/kid-brain.jpg" />
    <figcaption>Are you a doctor yet?</figcaption>
</figure>
<p>
    Maybe a child is a bad example. But what if we're talking aboout an adult? If we had the technology, why wouldn't we rewire their brain then? And the answer is: because we haven't a goddamn clue how to do that.
</p>
<p>
    The human brain may be the most advanced machine to have ever existed, but while we know in general what parts of the brain typically do what, no self-respecting neurosurgeon will ever claim to know which connections are responsible for processing specific information.
</p>
<p>
    This is because cerebral cortex starts off as a blank slate, with almost zero kowledge contained within. All the connections are in place and ready to go, but without having ever experienced the world, you can barely move, let alone paint landscapes or perform advanced calculus.
</p>
<p>
    Given brilliant and caring teachers to guide us though a life of trial and error though, our minds can be transformed from dense clouds of nerve cells into creative and computational machines. Machines which can take the same sensory information that a bird or a cat or a raccoon would receive and convert it into breathtaking masterpieces of art and science. All it takes it time and information.
</p>
<p>
    This concept of a cerebral cortex seems promising. If only we could accelerate the learning so that we didn't need to wait 18-20 years for a viable mind and all the roadblocks that can appear along the way. Roadblocks like fatigue, pain, hunger, sadness, distress. Roadblocks like humanity. So what if we removed the humanity from the equation by isolating this cloud of densely-interwoven nerve cells and then got to work collecting all the relevant information to a goal and developed new pedagogical approaches for this cleaner scenario?
</p>
<p>
    Congradulations, you've just conceived of the field of deep learning.
</p>
<p>
    Maybe now its understandable why AI researchers would never claim to have "designed" a system that performs a task, and why this lack of interjection gives them high hopes for training a machine to learn anything. After all, you were able to do it, weren't you?
</p>
<p>
    Even with this understanding of AI, you might need some more convincing of why this is "the most important topic of the 2020s"? That's a bit of a stretch, right? What about global warming? What about the housing crisis? What about wealth inequality? These are all extremely important issues. What makes AI is _the_ issue?
</p>
<p>
    So now let's walk through a variety of areas of life, all the while training our minds on:
        - what makes humans so efficient at performing these tasks?
        - what information is available to solve these tasks?
        - how can AI augment our abilities to perform these tasks, if not replace us altogether?
        - what are the implications for society?
    Hopefully the handful of bold predictions for advances we will see in the next 10 years will be enough to convince you. All that's left then is to show why everyone from politicians to your grandparents will start to question everything the very essence of what it means to be human and alive :)
</p>

<p>
    Advertising/Marketing
    What's the goal?
        - alert you to the presence of the product
        - find the right presentation of the product to convince a person like you to buy it
            - words, imagery
        - netflix already does this with images for tv shows.
            -They have a profile of you based on the videos you've seen and the ratings you've given
            (image describing what a traditionally butch 50-year-old sees vs what a 15 year old urban teenager sees for the same show's adverstisement)

    the only time a company seems to work towards people agreeing on a subject, it's when it's related to a product that said company is selling.

    netflix has two goals:
        - steering people toward to its own original content
        - keeping you on the app longer to increase your probability of consuming said original content

    what's the data?
        your previous purchases
        how interested to are in the product or similar products
        what kind of person you are
        how likely people like you are to buy such a product

    twitter, facebook, instagram
        what are you typing (not even what you finally type, but what you initially type and then erase too)
        how long you stay on a given part of the screen
            - how do they know that?
            - how often do you use facebook and twitter on your phone compared to your laptop?
            - how big are the ads on your phone and your laptop
            - they know

    these social media platforms *seem* different because they're not selling anything to you, but rather to companies who wish to promote their products. They are really doing the same thing:
        - steering you towards content that the creators have paid them to advertise
        - keeping you on the platform long enough to have you interact with them

    Here's a bold prediction: in this decade it will be possible for this scene to occur
    https://www.youtube.com/watch?v=uiDMlFycNrw
    it's rare for a film to under-estimate how advanced a technology would be in a given year (where the hell is my blade runner car)
    but in this case, it's well undershot what publci ads will be like in 2054
    but with further improvements like
    taking into account your mood
    your recent search history
    the system:
        ad companies get face data:
        ask for charater breakdown and moood
        voila
    possible (relate to GOVERNMENT)



    all those photos and videos of you in the cloud describing who you are and what you're doing
    Little cindy playing with her dog
    Michael drinking his fifth beer at the christmas party
    the images, the desrciptions, the links, the likes
    where you lingered, what you scrolled back to
    that's data
    It been converted to ones and zeros and its now sitting in a server farm somewhere, being processed and reprocessed over and over and in the process gulping in electrical energy and spitting out environmental nuisances
    and then they're going to use the amount of time you hover over certain ads or read certain articles to
    figure out how much you relate to people who've made purchases or how to turn you into someone who is more likely to buy this product
    marketting reaching inception levels
</p>

<p>
    Transportation

    # what's the goal?
    to move people and things from point A to point B?

    # why?

    people:
    working, shopping, events, sports, social interaction, ambience for reading and working

    all these are still going to exist at more 

    working, sports, social interaction, 

    goods:
    transportation from the production facility to the consumer

    services:
    get people to fix or do something for you (repair people, contractors)

    # what's the data?
    
        How do you figure out how to drive in any scenario:
        - collect information about environmental characteristics
        - collect information about driving behaviour
            - when you turn, how hard
            - when you stop, how hard
        - collect information about car state
        with all this information in all cars rolling of the lot from all vehicle producers
        you get a hivemind of driving behaviour and the results with respect to car damage
        it doesn't matter what area you live in, how much snow there is, how cold it is
        with enough data, a machine can be determine the optimal actions to take in any driving scenario

        I don't doubt that tesla has been collecting data on driving habits on all of its cars
        and potentially video recodings as well.
        If they are saying they aren't but they are and if and that's illegal, woah boy
        If not, I'd wager that they start paying their customers to collect that data soon

        In any case, this information is just ripe for the picking. all it takes is
        a massive tech company that they can just pay regular people to set up cameras
        and sensors in their car to collect all of this.

        given this data, like
            - steering
            - speed
            - road condition
            - car positions around you
        
        how could we ever say that a car couldn't drive like a human on an icy road
        when humans learned to do it (and still make mistakes)


    # what tools will exist?
    Drones (flying, driving and swimming)
    industry-wide vehicle to vehicle communication protocols (think D-Link vs WiFi)
    retro-fitted cars for self driving

    # How will governance affect it?
    I can imagine a driving test developped by governments explicitly for self
    driving cars
        - wet
        - icy
        - traffic jam (government spends 100 grand on 4 used cars that it can control remotely)


    don't limit this to cars
    flying drones
    any purchases you need to make could be served by drones
    uber has car drivers told where to go and where to take food to
    that driver is unnecesary
    ...so's that car. 
    with some sort of public record of flight paths for coordination, drones could easily perform this task
        - fly right over streets?
        - too much noise?
        - flying several hundred feet in the air is more likely
    so now the only reason you're going around is for live events and to work
    work: automated buses with custom routes depending on demand the night before
    - car sharing services become the norm 
    - professional drivers connected by a link to drone cars only in cases where an accident is signaled

    

</p>

<p>
    Medecine:
    # what's the goal?
    
    minimize the incidence and severity of health problems (mental and physical) in humans

    # why?

    why? people are evolutionally pre-disposed to wanting a long, healthy life ()

    # what's the data?

    this may very well be the biggest dataset (and the most illusive) on the plant
    birth weights
    vaccination records
    illnesses
    height
    weight
    heart rates
    blood pressure
    blood contents
    urine contents
    mood

    these are just a subset of the data caterogies that health authorities have at their disposal
    most are hand-written and forms differ in their content and structure from health authority to health authority
    but the data is there, just waiting to be compiled, categorized and quantified

    further than that, given enough scaling and efficiency improvements: DNA sequencing

    gut microbiome


    # what tools will exist?

    right now, there are countless thousands of people working on systems that:
        - detect any (ANY) illness in any body (if dogs can sniff out cancer, it's only a matter of time before a machine can)
        - find the structure of a chemical that is optimal for your genetics and illness
            - you can either opt in by providing your genetic records to the state or hope for the best with the median medication for this illness
        - perform surgery with micrometer percision (potentially even non-invasively)
    No matter how professional they are about it, it's awkward divulging our corporeal blights and malfunctions to anyone
    how much more accurate
    if the gut microbiome is that important, it's not hard to fathom a one-stop-shop toilet assay lab.
    go in, pee, poop, get analysis
    if they succeed, then all that's left is to feel like someone is paying attention to you, the social aspect of it all
    but why go to the doctor if you can have an app that asks a series of questions to give a result
    effectively triaging you in your own home
    live nurses are already doing that (phone line)
    cancer patients are already using such apps

    stores of gut flora and fauna used as prescriptions rather than drugs
    or a combination of each

    # How will governance affect it?
    what happens when a machine kills a mother of two in what's supposed to be routine surgery?
    it'll happen. Given 10,000 "routine" surgeries, at least one will be less than routine

    will companies be allowed to pass drugs that are related to previous drugs?

    what happens when a triage program misdiagnoses what turns out to be a serious problem?

    


</p>

<p>
    You cannot patent a neural net any more than you can patent a brain. That's
    because you did not design the neural net. If you did, it's probably not worth
    patenting. You can patent what comes out of the neural net, but 

    https://ipchimp.co.uk/2017/08/02/can-you-protect-artificial-intelligence-inventions-at-the-european-patent-office/
</p>

<p>
    Law enforcement

    # what's the goal?
    preventing harm to people and property in accordance with the written law
    identifying, locating and penalizing (bringing to justice) those who run afoul of the law

    # why?

    to ensure that the rights of every citizen are respected 

    # what's the data?

    Facial recognition
    video surveilance
    social network surveillance
    car information
    residence location
    

    # what tools will exist?

    home cameras are getting remarkably cheap
    When every car has locational data with timestamps and a great many cars have
    cameras out the ass, you can bet that police are going to start taking advantage of that

    your style of writing as almost its own kind of DNA. Every post on social networks can be parsed by
    language forensics to determine if a new user is a criminal

    cops wearing body cameras or AR goggles walking a beat

    # How will governance affect it?

    if you want to look at one possible future, basically look at china and uighurs
    we scoff at what's going on there, but remember that your government isn't that innocent.
    police dogs
    look at how far we've already come in terms of robot dexterity
    how far is another 10 years going to get us, especially when the demand is there from militaries that desire to replace faulty humans
    and police departments desire to be low-key militaries

    # Big Prediction
    China will use the knowledge and toolsets that they gain from 
    cars themselves will be used to police driving habits. 
    afforementioned vehicle to vehicle communication + cameras means that car chases don't matter any more. 
        - looking for a white honda civic, license plate BBBB918
        - chrome alert sent to cars
        - positive IDs sent to authaurities

    AR starts to seep into police forces, googles can quickly run facial checks on
    everyone in front of the police for matches in the criminal database
    
</p>

<p>
    Government and governance:
    here's where we hit the great unknown
    any other these changes require the go-ahead from a governing body
    you can understand why ontario would want to regulate the use of driverless cars when its human
    population can't go an hour without getting into an accident due to winter driving conditions
    and you can sure as hell guarantee that no hospital is going to let robots operator on human without a gargantuan safety net in place of a redefinition of mal-practice
    Do you have a neighbour who complains about every minor noise disturbance?
    Can you imagine what it will look like in new york city or toronto when people walk out of clubs on saturday morning or go out for lunch at noon and are hankering for food?
    Unless you can hide drones from eyes and ears, that's going to be a nuisance to the n-th degree
    tools to get the opinion of the people and faciltiate discussion
    the easy part has been making intelligent recommendation systems to take your initial feelings and make a charicature of yourself
    the hard part is going in the opposite direction: helping people understand a different perspective
    it'll happen, it'll be slow, but I have to hope that a good-hearted attempt to get people to listen to each other will be welcomed by the electorate

    the other side of things is that, when you compare a private to a public institution, the rate of evolution and adoption of
    best practices is laughably slow.


</p>

<p>
    Politics
    this is about to get fucked. Real fucked.
    This decade is going to start out with trust in politics and policians at abysmal levels
    Throw in deepfakes and coersive ads meant to draw out the worst in people and you've got yourself a bona-fide dumpster fire on capital hill
    The ability to win over people with understanding and leadership will take a back seat to your ability to slam, destroy and obliterate the other side with hot takes.

    # what's the goal?

    to get elected

    # why?

    power*
    collect a hefty paycheck*
    help friends, family, people like you get ahead*
    maybe even (fingers crossed) shape government based on:
        - the will of your consituents
        - the livelihoods of current and future generations
        - the unheard voices of your riding
        - a dream for a more equitable future
        
    
    # what's the data?

    If politics in recent years have shown us anything, it's the I can tell you
    to go look at adverstisement and marketting and call it a day.

    # what tools will exist?

    fundraisers


    # How will governance affect it?



</p>

<p>
    Credit Systems
    every purchase we make with our credit cards is an extra data point 
    there's no reason to think this will stop at spending habits though
    again, china is the pinnacle of what could be here
    they have a captive population on which to test all this surveilance
    and if you remember one thing about AI, let it be this: more data = better results, and there are 10 million walking, talking data producers in XinJiang 
</p>

<p>
    Economics
    Maybe you have a co-worker who goes on about stock picks
    Maybe they're a stick-to-the-basics fundamentals investor
    Maybe they evangelize trendlines, taking their ruler out to figure out when a stock is going to "meet resistance"
    Can this be automated?
    Oh hell yeah. It's already been done
    in fact, given our trend towards (semi-)robo-advisors investing in ETFs for us
    Someone stands to make a lot of money not in understanding how the market functions, but in understanding the behaviour of the tools being used to invest
    right now there's a lot of chatter surrounding climate- and socially-concious ETFs because millenials are starting to take all that money they're earning and investing,
    I don't know if you've been asleep for the past 5 years, but they like diversity, feminism and trying not to burn to death
    gen z isn't likely to regress in those ideas
    so with that in mind, people stand to make a lot of money by investing in stocks or indexes that they'll like
    Take that same approach, but instead of observing humans, use machine learning to learn what the machines themselves are thinking
    Computer vision to check parking lots or maybe even makes of cars
</p>

<p>
    Art
    Paintings are already selling
    Original, compelling stories (though rare these days even in the human realm) seem out of the AI, but
    much of the popular music is formulaic enough that it or something like it could be produced by AI
    The ultimate aim of music production companies is to get as much profit from the audio as they can 
    I can envision music producers moving from fiddling knobs in the studio to fiddling knobs on a neural network


    what does it take to make a piece of art? I would argue that there are two principal components:
    - an intuition for an inspirational or provocation
    - a "voice" with which one may inspire or provoke

    take a million artists
    show each of them a million images
    ask them if they are inspired or provoked

    you now have a machine that can identify inspirational or provocative subjet matter

    break down art into its consituent categories:
    - performance
    - painting
    - sculpture
    - etc

    input these works into a machine learner

    you know have a thing that can create art

    We can look at this two ways:
    - all art is subjective in quality, in which case there's absolutely no argument against a machine artists producing moving works
    - good works of art share some objective properties, in which case see the above

    

</p>

<p>
    Sport

    # what's the goal?

    win as many games are you can as often as you can
    It's tempting to look at the relationship between winning and money as the means and end, respctively, but
    "make more money" is a smidge broad as a goal and there's no one aspect of a team or player as closely related to
    revenue as winning

    Sure, the yankees might still make more money than the Blue Jays even at the bottom of the AL East, but they'll sure as hell make more money
    if they win 100% of their games and sweep the playoffs.

    For those who still want to argue that the ultimate goal is to make money from a product, you're in luck: scroll up the page.
 
    # why?

    more asses in seats and eyeballs on screens leads to
        - higher ticket sales (and potentially costs when demand exceeds supply)
        - charging more for broadcast rights
        - charging more for endorsemenets and merchandising

    all of which lead to higher revenue   

    # what's the data?

    - game state:
        - score
        - time remaining
        - 
    - players on the field
    - their
        - locations
        - momentum
        - time on ice


    # what tools will exist?

    a lot of what makes star athletes stars is the intuition and instinct they possess

    Take your Tom Brady's, your Wayne Gretzky's, your Michael Jordan's.

    What if you could program that intuition into a tool and that tool would tell you -- in real time -- where to go and what to do

    After that, all that's left is to convert your body into the ideal form through training and then practice as much as possible

    The only use for a coach is to describe to you why you were told to do what you did such that you internalize the connection between states and actions and why theyère important

    Remember that we did not evolve to be good at sports, we simply evolved to a point where organized sport was possible
    
    # How will governance affect it?

    As long as its kept to practices, there aren't going to be any complaints

    it would definitely be interesting to provide heads up displays to players though. 

    AR is a thing
    tiny cameras are a thing
    AI processing of sports videos is a thing
    if you're a billion-dollar enterprise like the Dallas Cowboys and someone comes up to you and tells you that
    you can conduct your practice by outfitting each of your players with an AR visor that will alert them to where they should be focusing at any given moment based on their current field of view
    you'll spend tens of millions of dollars on such a system
    because you know that even a slight bump in spacial awareness and intuition would be worth the difference

    let's take hockey for an example
    you're practicing and you take the puck into a set defensive play
    the AR could singal any of the following:
        - defenseman making a move toward you
        - dump and chase
        - move to the left

    this may even start with sports schools for younger players, since internalization
    of situational awareness is paramount for making that leap from a kid who's pretty good at hockey to one who can predict plays
    before their opponents even know they're going to make those plays themselves
</p>

<p>
    Environment
    there's two ways to look at this:
    efficiency and energy use

    AI models are not born in a vaccuum
    they require extensive research for what datasets, data processing and model characteristics are required
    the more data the better, too
    all this data needs to be accessed and modified by many people in a team -> servers
    and you need to train models, which is a highly resource intensive process
    you need to train new researchers as well, so more data and more models -> servers
    only a fraction of countries are really in this game right now, so we can imagine how much more energy is going to be expended by server farms (both private and communal)
    the thing is, all this initial energy expenditure in creating models will lead to energy savings due to increased efficiency in the final product (e.g., farm equipment)
</p>

<p>
    Philosophy
    This will be the decade where the question of what it means to be alive escapes the halls of Philosophy departments, seeping into the collective consciousness.

    https://www.nbcnews.com/mach/science/rise-smart-machines-puts-spotlight-robot-rights-ncna825791?icid=related

    As cognitive scientists get a clearer picture of how any why we do what we do
    data scientists concoct ambitious means for collected and processing the wealth of data on human behaviour
    seemingly unrelated curriculums start to incorporate AI into their courses
    AI chipmakers pack more firepower into cheaper GPUs
    APIs and other tools are created to introduce a new, tech-savvy generation to AI
    we're going to start pumping out some models that acheive feats that we so narcissiticly assumed were unique to us.
    What then? When just for the hell of it, undergrads at MIT produce a voice assistant that can use as its input the emotional state of its owner to determine what sort of tone to affect and what sort of things to say to them to bring them back to a point of happiness (link to Her).
    If we can ask that AI how it feels about being shut off and 100% of the time it says that is afraid or scared or sad, does that not count for something
    Such an AI is always taking input that modifies the energy allocations in certain parts of its "brain"
    It's not always reacting, but are the fluctuations of energy in that software not unspoken "thoughts"?
    "Asma sounds unhappy. Not devastated, just down. Ask her what's on her mind once she's not busy"

    That's a thought.
</p>
<p>
    There's a great unknown in this scenario though. Take away every outward expression of your thoughts and emotions:
    the words and tone you use to speak, your body language, your facial expressions. In the absence of such
    information, how can anyone know what you're thinking when you're performing your tasks? You could -- in theory --
    be thinking very discriminatory and hurtful thoughts as you process the information and no one would ever know until
    they asked you your opinion. And in the abscence of knowing for sure what about the brain is responsible for these
    thoughts, <a href="https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/"
        target="_blank">all you can really do is self-sensor</a>.
</p>
<p>
    Now that you have a better handle on and the negative impacts that these tools have had on us, but keep in mind that
    we know exactly how these tools
    function, they are built from discrete subsystem that we can inspect and disect, with every problem having a set of
    definitive sources (improper routing, blown fuse). The principal source of all the *real* issues related to these
    tools
    is and always will be the brains interacting with them. The difference now is that we don't fully understand the
    tool
    we're interacting with. If something goes wrong, there's no discrete set of parts that we can point to and say
    "there's
    your problem." We provide a goal, design a network, feed in data, monitor results and wait until we get the ones we
    want. It is, in effect, a brain itself that we're interacting with. A brain less complex than ours for the moment,
    but a
    brain nonetheless, constantly reacting to the input we provide it to modify the results in an everevolving feedback
    loop
    between two brains.
</p>
<p>
    That's all harmless when you have a very limited goal like <i>identify the thing in the photo</i> (although even
    that can go horrificly wrong). What happens when the goal becomes more abstract, like "find a video that will keep
    this person watching", or even more broadly, "identify someone breaking the law"?
</p>
<p>
    we could poke and prod individually to solve any problems that might arise. that we build with a complete
    understanding of how they function. When they malfunctioned, we had a blueprint of their design and we were
    confident , the process , and it was the add-ons or purposeful abuses that caused the problems. We absolutely cannot
    say that with AI.
    Not: turn chemical energy in to physical momentum
    not: all people to communicate through computers
    just: recommend people stuff they've like based on what they already like
    a car engine isn't going to turn itself on and drive off a cliff
    but we don't necessarily know all the weightings of connections in a neural net that will produce a scenario that
    arrives at the intended goal
    We've made a meseeks box, which is amazing, the problem is that when presented with a shiny new tool, we tend more
    toward the Jerry side of the spectrum rather than the cautious, reasoned approach that is necessary.

</p>

<p>
    The only thing I know for sure is that only about 20% of these things will happen.
</p>

{% endblock %}