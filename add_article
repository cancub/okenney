#! /usr/bin/env python

import copy
import cv2
import datetime
import html.parser as HTMLParser
import os
import re
import sys
import shutil

from app import db
import app.mod_articles as _articles
from app.mod_articles.models import Article

'''
TODO:
- Use relational database for categories
- use argparse
'''

CATEGORIES = ['about', 'ideas', 'politics', 'philosophy', 'projects']
MAIN_ARTICLE_SUBDIR = 'main'
MAIN_ARTICLE_TEXT_NAME = 'main.html'
MAIN_ARTICLE_IMAGE_NAME = 'main.png'
BIG_IMAGE_HEIGHT = 600
BIG_IMAGE_WIDTH = 1000
SMALL_IMAGE_SCALE = 0.15
IMAGE_NAME = 'principal'
IMAGE_BIG_NAME = IMAGE_NAME + '-gd.png'
IMAGE_SMALL_NAME = IMAGE_NAME + '-pt.png'

class HTMLWordCounter(HTMLParser.HTMLParser):
    def __init__(self):
        super(HTMLWordCounter, self).__init__()
        self.word_count = 0
    def handle_data(self, data):
        if self.get_starttag_text() != 'script':
            self.word_count += len(data.split())

def get_saved_title(title):
    # Make the title lower case to look nicer in the directory.
    title = title.lower()

    # Remove articles ,conjunctions, non-letter characters and convert spaces to
    # dash
    letter_neg_lookbehind = '(?<!\w)'
    letter_neg_lookahead = '(?!\w)'
    title = re.sub(
        ('{0}[tT]he{1}|{0}[oO]f{1}|{0}[aA]nd{1}|{0}a{1}|{0}[Aa]{1}|'
         '[$-/:-?{{-~!"^_`\[\]]').format(
            letter_neg_lookbehind,
            letter_neg_lookahead,
        ),
        '',
        title
    )

    # Remove the spaces from the end.
    title = title.rstrip()

    # Locate the individual words remaining
    p = re.compile(r'\w+')
    title_words = p.findall(title)

    # Crop it down to the first 5 words or whatever number of words there are,
    # whichever is smaller
    title_length = min(5, len(title_words))

    return '-'.join(title_words[:title_length])

def get_word_count(html_text):
    counter = HTMLWordCounter()
    counter.feed(html_text)

    return counter.word_count

def get_crop_dims(actual_dim, desired_dim):
    to_crop = (actual_dim - desired_dim) / 2

    # No need to crop if we're already at the right dimension.
    if to_crop == 0:
        return 0, actual_dim

    int_crop = int(to_crop)
    if int_crop == to_crop:
        # We're dealing with a whole number, which means we can crop the same
        # amount from each side.
        crop_high = crop_low = int_crop
    else:
        # We're dealing with a fraction. Round down for the high and round
        # up for the low.
        crop_high = int_crop
        crop_low = int_crop + 1

    return crop_low, actual_dim - crop_high

def build_images(path):
    image_big = cv2.imread(path)

    height, width, _ = image_big.shape

    # Scale dimension closest to the desired aspect ratio of 1000 x 600
    height_scale = BIG_IMAGE_HEIGHT / height
    width_scale = BIG_IMAGE_WIDTH / width

    if width_scale < height_scale:
        # The height is closer than the width to its respective dimension in
        # the desired aspect ratio. So it's better to scale the height to
        # the desired height and crop the width.
        dx = int(width * height_scale)
        dy = BIG_IMAGE_HEIGHT
    else:
        # The opposite is true.
        dx = BIG_IMAGE_WIDTH
        dy = int(height * width_scale)

    # Scale the image
    image_big = cv2.resize(image_big, (dx, dy))

    # Prepare for the crop. Only one of these dimentions witll be changed.
    height_crop_low = 0
    height_crop_high = image_big.shape[0]
    width_crop_low = 0
    width_crop_high = image_big.shape[1]

    if dy == BIG_IMAGE_HEIGHT:
        # We scaled to the height, so we need to crop to the width.
        width_crop_low, width_crop_high = get_crop_dims(
            width_crop_high,
            BIG_IMAGE_WIDTH,
        )
    else:
        # We scaled to the width, so we need to crop to the height.
        height_crop_low, height_crop_high = get_crop_dims(
            height_crop_high,
            BIG_IMAGE_HEIGHT,
        )

    # Crop and center to this aspect ratio.
    image_big = image_big[
        height_crop_low:height_crop_high,
        width_crop_low:width_crop_high,
        :
    ]

    # Make a copy and scale it down.
    image_small = cv2.resize(
        copy.copy(image_big),
        (0, 0),
        fx=SMALL_IMAGE_SCALE,
        fy=SMALL_IMAGE_SCALE,
    )

    return image_big, image_small

def build_paths(category, title):
    # make the directories that the files will be stored in an all intermediary
    # directories.
    images_dir = _articles.article_images_dir_path(
        category,
        title,
        remote=False,
    )
    article_dir = _articles.article_category_path(category, remote=False)
    for directory in (images_dir, article_dir):
        try:
            os.makedirs(directory)
        except FileExistsError:
            pass

    return os.path.join(article_dir, title + '.html'), images_dir

def process_article(contents, images_dir):
    # Use a regex to replace each image filename with the full path for the
    # file.
    return re.sub(
        r'(image_et_legende\(.*?\)\s*-*%}\s*)(.*?)(\s*{%\s+endcall)',
        fr'\1<img src="{images_dir}/\2"/>\3',
        contents,
    )


root_article_dir = os.path.abspath(sys.argv[1])
category = sys.argv[2]

if not os.path.isdir(root_article_dir):
    raise Exception('No directory exists at {}'.format(root_article_dir))

if category not in CATEGORIES:
    raise Exception('Unknown category "{}"'.format(category))

# There must be a subdirectory within the specified directory which contains
# the article as well as the main image.
main_article_dir = os.path.join(root_article_dir, MAIN_ARTICLE_SUBDIR)

if not os.path.isdir(main_article_dir):
    raise Exception('No subdirectory exists at {}'.format(main_article_dir))

# Locate the first .html file we can find in the subdir.
text_path = os.path.join(main_article_dir, MAIN_ARTICLE_TEXT_NAME)
image_path = os.path.join(main_article_dir, MAIN_ARTICLE_IMAGE_NAME)

if not os.path.exists(text_path):
    raise Exception('No article exists at {}'.format(text_path))
if not os.path.exists(image_path):
    raise Exception('No image exists at {}'.format(image_path))

contents = _articles.ArticleContents(text_path)

# Locate the title within the file and collect the word count.
title = get_saved_title(contents.en.title)
word_count = get_word_count(contents.en.text)

# Load the images
image_big, image_small = build_images(image_path)

now = datetime.datetime.now()

# Build the directory for both images and templates.
article_path, images_dir = build_paths(category, title)

# Store the article in the specified directory under the title.
if os.path.exists(article_path):
    raise FileExistsError('We already wrote an article with that name')

# Convert the image filename strings to <img> elements within the file and
# return the processed article contents.
processed_article_contents = process_article(
    contents.contents,
    f'/{_articles.PROJECT_IMAGES_PATH}/{category}/{title}'
)

# Write the processed file to its new home.
with open(article_path, 'w') as F:
    F.write(processed_article_contents)

# Store the large and small image files in the images directory.
cv2.imwrite(os.path.join(images_dir, IMAGE_BIG_NAME), image_big)
cv2.imwrite(os.path.join(images_dir, IMAGE_SMALL_NAME), image_small)

# Copy each of the remaining files to the article's image directory.
for fname in os.listdir(root_article_dir):
    fpath = os.path.join(root_article_dir, fname)

    if os.path.isdir(fpath):
        continue

    shutil.copy(fpath, os.path.join(images_dir, fname))

# Store this information in the database
db.session.add(
    Article(name=title, category=category, dtime=now, word_count=word_count)
)
db.session.commit()

# Print out the path the for the article as well as the directory in which its
# images are stored.
print(article_path)
print(images_dir)
